{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import pickle as pkl\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(folder_path, label): \n",
    "    scores = []\n",
    "    data_list = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            scores.append(int(file[file.find(\"_\")+1:file.find(\".\")]))\n",
    "            with open(folder_path+file) as f:\n",
    "                data_list.append(f.read())\n",
    "    \n",
    "    labels = label*np.ones(len(scores))\n",
    "    return data_list, labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_data(data1, data2, label1, label2, score1, score2, split, shuffle, train_size=20000):\n",
    "    data = data1+data2\n",
    "    labels = np.concatenate([label1, label2]).tolist()\n",
    "    scores = score1+score2\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.seed(0)\n",
    "        index = np.random.permutation(len(data))\n",
    "        data = np.array(data)[index].tolist()\n",
    "        labels = np.array(labels)[index].tolist()\n",
    "        scores = np.array(scores)[index].tolist()\n",
    "    \n",
    "    if split:\n",
    "        train_data = data[:train_size]\n",
    "        val_data = data[train_size:]\n",
    "        train_labels = labels[:train_size]\n",
    "        val_labels = labels[train_size:]\n",
    "        train_scores = scores[:train_size]\n",
    "        val_scores = scores[train_size]\n",
    "        return train_data, train_labels, train_scores, val_data, val_labels, val_scores\n",
    "    \n",
    "    return data, labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_path = os.getcwd()+'/aclImdb/train/pos/'\n",
    "train_neg_path = os.getcwd()+'/aclImdb/train/neg/'\n",
    "test_pos_path = os.getcwd()+'/aclImdb/test/pos/'\n",
    "test_neg_path = os.getcwd()+'/aclImdb/test/neg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_data, train_pos_label, train_pos_scores = load_data(train_pos_path, 1)\n",
    "train_neg_data, train_neg_label, train_neg_scores = load_data(train_neg_path, 0)\n",
    "test_pos_data, test_pos_label, test_pos_scores = load_data(test_pos_path, 1)\n",
    "test_neg_data, test_neg_label, test_neg_scores = load_data(test_neg_path, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_data, train_labels, train_scores, \\\n",
    "# val_data, val_labels, val_scores = merge_data(train_pos_data, train_neg_data, train_pos_label, train_neg_label,\n",
    "#                                               train_pos_scores, train_neg_scores, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data, test_labels, test_scores = \\\n",
    "merge_data(test_pos_data, test_neg_data, test_pos_label, test_neg_label,\n",
    "                                              test_pos_scores, test_neg_scores, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pkl.dump(train_data, open(\"train_data.p\", \"wb\"))\n",
    "# pkl.dump(train_labels, open(\"train_labels.p\", \"wb\"))\n",
    "# pkl.dump(train_scores, open(\"train_scores.p\", \"wb\"))\n",
    "# pkl.dump(val_data, open(\"val_data.p\", \"wb\"))\n",
    "# pkl.dump(val_labels, open(\"val_labels.p\", \"wb\"))\n",
    "# pkl.dump(val_scores, open(\"val_scores.p\", \"wb\"))\n",
    "train_data = pkl.load(open(\"train_data.p\", \"rb\"))\n",
    "train_labels = pkl.load(open(\"train_labels.p\", \"rb\"))\n",
    "train_scores = pkl.load(open(\"train_scores.p\", \"rb\"))\n",
    "val_data = pkl.load(open(\"val_data.p\", \"rb\"))\n",
    "val_labels = pkl.load(open(\"val_labels.p\", \"rb\"))\n",
    "val_scores = pkl.load(open(\"val_scores.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing (Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def tokenize(sent, tokenization):\n",
    "    tokens = tokenizer(sent)\n",
    "    if tokenization:\n",
    "        return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "    else:\n",
    "        return [token.text for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-gram (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset, tokenization):\n",
    "    token_dataset = []\n",
    "    all_tokens = []\n",
    "    \n",
    "    for sample in dataset:\n",
    "        tokens = tokenize(sample, tokenization)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "\n",
    "    return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 4809135\n"
     ]
    }
   ],
   "source": [
    "train_data_tokens = pkl.load(open(\"train_data_tokens.p\", \"rb\"))\n",
    "all_train_tokens = pkl.load(open(\"all_train_tokens.p\", \"rb\"))\n",
    "val_data_tokens = pkl.load(open(\"val_data_tokens.p\", \"rb\"))\n",
    "test_data_tokens = pkl.load(open(\"test_data_tokens.p\", \"rb\"))\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens)))\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-gram (word) no tokenization (lowercase & remove punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 5439707\n"
     ]
    }
   ],
   "source": [
    "train_data_tokens_ntk = pkl.load(open(\"train_data_tokens_ntk.p\", \"rb\"))\n",
    "all_train_tokens_ntk = pkl.load(open(\"all_train_tokens_ntk.p\", \"rb\"))\n",
    "val_data_tokens_ntk = pkl.load(open(\"val_data_tokens_ntk.p\", \"rb\"))\n",
    "test_data_tokens_ntk = pkl.load(open(\"test_data_tokens_ntk.p\", \"rb\"))\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens_ntk)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens_ntk)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens_ntk)))\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens_ntk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_dataset_ngram(dataset, n, tokenization):\n",
    "    token_dataset = []\n",
    "    all_tokens = []\n",
    "    \n",
    "    for sample in dataset:\n",
    "        tokens = tokenize(sample, tokenization)\n",
    "        n_grams = list(ngrams(tokens, n))\n",
    "        token_dataset.append(n_grams)\n",
    "        all_tokens += n_grams\n",
    "\n",
    "    return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 4789135\n"
     ]
    }
   ],
   "source": [
    "train_data_tokens_n2 = pkl.load(open(\"train_data_tokens_n2.p\", \"rb\"))\n",
    "all_train_tokens_n2 = pkl.load(open(\"all_train_tokens_n2.p\", \"rb\"))\n",
    "val_data_tokens_n2 = pkl.load(open(\"val_data_tokens_n2.p\", \"rb\"))\n",
    "test_data_tokens_n2 = pkl.load(open(\"test_data_tokens_n2.p\", \"rb\"))\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens_n2)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens_n2)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens_n2)))\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens_n2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-grams no tokenization (lowercase & remove punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 5419707\n"
     ]
    }
   ],
   "source": [
    "train_data_tokens_n2_ntk = pkl.load(open(\"train_data_tokens_n2_ntk.p\", \"rb\"))\n",
    "all_train_tokens_n2_ntk = pkl.load(open(\"all_train_tokens_n2_ntk.p\", \"rb\"))\n",
    "val_data_tokens_n2_ntk = pkl.load(open(\"val_data_tokens_n2_ntk.p\", \"rb\"))\n",
    "test_data_tokens_n2_ntk = pkl.load(open(\"test_data_tokens_n2_ntk.p\", \"rb\"))\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens_n2_ntk)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens_n2_ntk)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens_n2_ntk)))\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens_n2_ntk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 4769135\n"
     ]
    }
   ],
   "source": [
    "train_data_tokens_n3 = pkl.load(open(\"train_data_tokens_n3.p\", \"rb\"))\n",
    "all_train_tokens_n3 = pkl.load(open(\"all_train_tokens_n3.p\", \"rb\"))\n",
    "val_data_tokens_n3 = pkl.load(open(\"val_data_tokens_n3.p\", \"rb\"))\n",
    "test_data_tokens_n3 = pkl.load(open(\"test_data_tokens_n3.p\", \"rb\"))\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens_n3)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens_n3)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens_n3)))\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens_n3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-grams no tokenization (lowercase & remove punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 5399707\n"
     ]
    }
   ],
   "source": [
    "train_data_tokens_n3_ntk = pkl.load(open(\"train_data_tokens_n3_ntk.p\", \"rb\"))\n",
    "all_train_tokens_n3_ntk = pkl.load(open(\"all_train_tokens_n3_ntk.p\", \"rb\"))\n",
    "val_data_tokens_n3_ntk = pkl.load(open(\"val_data_tokens_n3_ntk.p\", \"rb\"))\n",
    "test_data_tokens_n3_ntk = pkl.load(open(\"test_data_tokens_n3_ntk.p\", \"rb\"))\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens_n3_ntk)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens_n3_ntk)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens_n3_ntk)))\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens_n3_ntk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 4749135\n"
     ]
    }
   ],
   "source": [
    "train_data_tokens_n4 = pkl.load(open(\"train_data_tokens_n4.p\", \"rb\"))\n",
    "all_train_tokens_n4 = pkl.load(open(\"all_train_tokens_n4.p\", \"rb\"))\n",
    "val_data_tokens_n4 = pkl.load(open(\"val_data_tokens_n4.p\", \"rb\"))\n",
    "test_data_tokens_n4 = pkl.load(open(\"test_data_tokens_n4.p\", \"rb\"))\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens_n4)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens_n4)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens_n4)))\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens_n4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-grams no tokenization (lowercase & remove punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 5379707\n"
     ]
    }
   ],
   "source": [
    "train_data_tokens_n4_ntk = pkl.load(open(\"train_data_tokens_n4_ntk.p\", \"rb\"))\n",
    "all_train_tokens_n4_ntk = pkl.load(open(\"all_train_tokens_n4_ntk.p\", \"rb\"))\n",
    "val_data_tokens_n4_ntk = pkl.load(open(\"val_data_tokens_n4_ntk.p\", \"rb\"))\n",
    "test_data_tokens_n4_ntk = pkl.load(open(\"test_data_tokens_n4_ntk.p\", \"rb\"))\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens_n4_ntk)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens_n4_ntk)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens_n4_ntk)))\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens_n4_ntk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocab lists and transform data into indices lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(all_tokens, max_vocab_size):\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token2index_dataset(tokens_data, token2id):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-gram (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 25000\n",
    "token2id_n1, id2token_n1 = build_vocab(all_train_tokens, max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "train_data_indices_n1 = token2index_dataset(train_data_tokens, token2id_n1)\n",
    "val_data_indices_n1 = token2index_dataset(val_data_tokens, token2id_n1)\n",
    "test_data_indices_n1 = token2index_dataset(test_data_tokens, token2id_n1)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices_n1)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices_n1)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices_n1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-gram (word) no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 25000\n",
    "token2id_n1_ntk, id2token_n1_ntk = build_vocab(all_train_tokens_ntk, max_vocab_size = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "train_data_indices_n1_ntk = token2index_dataset(train_data_tokens_ntk, token2id_n1_ntk)\n",
    "val_data_indices_n1_ntk = token2index_dataset(val_data_tokens_ntk, token2id_n1_ntk)\n",
    "test_data_indices_n1_ntk = token2index_dataset(test_data_tokens_ntk, token2id_n1_ntk)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices_n1_ntk)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices_n1_ntk)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices_n1_ntk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 25000\n",
    "token2id_n2, id2token_n2 = build_vocab(all_train_tokens_n2, max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "train_data_indices_n2 = token2index_dataset(train_data_tokens_n2, token2id_n2)\n",
    "val_data_indices_n2 = token2index_dataset(val_data_tokens_n2, token2id_n2)\n",
    "test_data_indices_n2 = token2index_dataset(test_data_tokens_n2, token2id_n2)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices_n2)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices_n2)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices_n2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-grams no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 25000\n",
    "token2id_n2_ntk, id2token_n2_ntk = build_vocab(all_train_tokens_n2_ntk, max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "train_data_indices_n2_ntk = token2index_dataset(train_data_tokens_n2_ntk, token2id_n2_ntk)\n",
    "val_data_indices_n2_ntk = token2index_dataset(val_data_tokens_n2_ntk, token2id_n2_ntk)\n",
    "test_data_indices_n2_ntk = token2index_dataset(test_data_tokens_n2_ntk, token2id_n2_ntk)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices_n2_ntk)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices_n2_ntk)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices_n2_ntk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 25000\n",
    "token2id_n3, id2token_n3 = build_vocab(all_train_tokens_n3, max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "train_data_indices_n3 = token2index_dataset(train_data_tokens_n3, token2id_n3)\n",
    "val_data_indices_n3 = token2index_dataset(val_data_tokens_n3, token2id_n3)\n",
    "test_data_indices_n3 = token2index_dataset(test_data_tokens_n3, token2id_n3)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices_n3)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices_n3)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices_n3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-grams no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 25000\n",
    "token2id_n3_ntk, id2token_n3_ntk = build_vocab(all_train_tokens_n3_ntk, max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "train_data_indices_n3_ntk = token2index_dataset(train_data_tokens_n3_ntk, token2id_n3_ntk)\n",
    "val_data_indices_n3_ntk = token2index_dataset(val_data_tokens_n3_ntk, token2id_n3_ntk)\n",
    "test_data_indices_n3_ntk = token2index_dataset(test_data_tokens_n3_ntk, token2id_n3_ntk)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices_n3_ntk)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices_n3_ntk)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices_n3_ntk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 25000\n",
    "token2id_n4, id2token_n4 = build_vocab(all_train_tokens_n4, max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "train_data_indices_n4 = token2index_dataset(train_data_tokens_n4, token2id_n4)\n",
    "val_data_indices_n4 = token2index_dataset(val_data_tokens_n4, token2id_n4)\n",
    "test_data_indices_n4 = token2index_dataset(test_data_tokens_n4, token2id_n4)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices_n4)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices_n4)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices_n4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-grams no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 25000\n",
    "token2id_n4_ntk, id2token_n4_ntk = build_vocab(all_train_tokens_n4_ntk, max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "train_data_indices_n4_ntk = token2index_dataset(train_data_tokens_n4_ntk, token2id_n4_ntk)\n",
    "val_data_indices_n4_ntk = token2index_dataset(val_data_tokens_n4_ntk, token2id_n4_ntk)\n",
    "test_data_indices_n4_ntk = token2index_dataset(test_data_tokens_n4_ntk, token2id_n4_ntk)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices_n4_ntk)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices_n4_ntk)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices_n4_ntk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NewsGroupDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when yo-u call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def newsgroup_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1-gram (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset_n1 = NewsGroupDataset(train_data_indices_n1, train_labels)\n",
    "train_loader_n1 = torch.utils.data.DataLoader(dataset=train_dataset_n1, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset_n1 = NewsGroupDataset(val_data_indices_n1, val_labels)\n",
    "val_loader_n1 = torch.utils.data.DataLoader(dataset=val_dataset_n1, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset_n1 = NewsGroupDataset(test_data_indices_n1, test_labels)\n",
    "test_loader_n1 = torch.utils.data.DataLoader(dataset=test_dataset_n1, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-gram (word) no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset_n1_ntk = NewsGroupDataset(train_data_indices_n1_ntk, train_labels)\n",
    "train_loader_n1_ntk = torch.utils.data.DataLoader(dataset=train_dataset_n1_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset_n1_ntk = NewsGroupDataset(val_data_indices_n1_ntk, val_labels)\n",
    "val_loader_n1_ntk = torch.utils.data.DataLoader(dataset=val_dataset_n1_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset_n1_ntk = NewsGroupDataset(test_data_indices_n1_ntk, test_labels)\n",
    "test_loader_n1_ntk = torch.utils.data.DataLoader(dataset=test_dataset_n1_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset_n2 = NewsGroupDataset(train_data_indices_n2, train_labels)\n",
    "train_loader_n2 = torch.utils.data.DataLoader(dataset=train_dataset_n2, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset_n2 = NewsGroupDataset(val_data_indices_n2, val_labels)\n",
    "val_loader_n2 = torch.utils.data.DataLoader(dataset=val_dataset_n2, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset_n2 = NewsGroupDataset(test_data_indices_n2, test_labels)\n",
    "test_loader_n2 = torch.utils.data.DataLoader(dataset=test_dataset_n2, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-grams no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset_n2_ntk = NewsGroupDataset(train_data_indices_n2_ntk, train_labels)\n",
    "train_loader_n2_ntk = torch.utils.data.DataLoader(dataset=train_dataset_n2_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset_n2_ntk = NewsGroupDataset(val_data_indices_n2_ntk, val_labels)\n",
    "val_loader_n2_ntk = torch.utils.data.DataLoader(dataset=val_dataset_n2_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset_n2_ntk = NewsGroupDataset(test_data_indices_n2_ntk, test_labels)\n",
    "test_loader_n2_ntk = torch.utils.data.DataLoader(dataset=test_dataset_n2_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset_n3 = NewsGroupDataset(train_data_indices_n3, train_labels)\n",
    "train_loader_n3 = torch.utils.data.DataLoader(dataset=train_dataset_n3, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset_n3 = NewsGroupDataset(val_data_indices_n3, val_labels)\n",
    "val_loader_n3 = torch.utils.data.DataLoader(dataset=val_dataset_n3, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset_n3 = NewsGroupDataset(test_data_indices_n3, test_labels)\n",
    "test_loader_n3 = torch.utils.data.DataLoader(dataset=test_dataset_n3, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-grams no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset_n3_ntk = NewsGroupDataset(train_data_indices_n3_ntk, train_labels)\n",
    "train_loader_n3_ntk = torch.utils.data.DataLoader(dataset=train_dataset_n3_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset_n3_ntk = NewsGroupDataset(val_data_indices_n3_ntk, val_labels)\n",
    "val_loader_n3_ntk = torch.utils.data.DataLoader(dataset=val_dataset_n3_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset_n3_ntk = NewsGroupDataset(test_data_indices_n3_ntk, test_labels)\n",
    "test_loader_n3_ntk = torch.utils.data.DataLoader(dataset=test_dataset_n3_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset_n4 = NewsGroupDataset(train_data_indices_n4, train_labels)\n",
    "train_loader_n4 = torch.utils.data.DataLoader(dataset=train_dataset_n4, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset_n4 = NewsGroupDataset(val_data_indices_n4, val_labels)\n",
    "val_loader_n4 = torch.utils.data.DataLoader(dataset=val_dataset_n4, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset_n4 = NewsGroupDataset(test_data_indices_n4, test_labels)\n",
    "test_loader_n4 = torch.utils.data.DataLoader(dataset=test_dataset_n4, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4-grams no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset_n4_ntk = NewsGroupDataset(train_data_indices_n4_ntk, train_labels)\n",
    "train_loader_n4_ntk = torch.utils.data.DataLoader(dataset=train_dataset_n4_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset_n4_ntk = NewsGroupDataset(val_data_indices_n4_ntk, val_labels)\n",
    "val_loader_n4_ntk = torch.utils.data.DataLoader(dataset=val_dataset_n4_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset_n4_ntk = NewsGroupDataset(test_data_indices_n4_ntk, test_labels)\n",
    "test_loader_n4_ntk = torch.utils.data.DataLoader(dataset=test_dataset_n4_ntk, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of N-gram Model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BagOfNgram(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfNgram classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(BagOfNgram, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim, 2)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        # return logits\n",
    "        out = self.linear(out.float())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    \n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_proc(model, train_loader, val_loader, lr, adj, ep, optim, lr_decay=0, plt=False):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if optim == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    \n",
    "    if adj:\n",
    "        scheduler = StepLR(optimizer, step_size=1, gamma=lr_decay)\n",
    "    \n",
    "    train_ls = []\n",
    "    for epoch in range(ep):\n",
    "        if adj:\n",
    "            scheduler.step()\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_ls.append(loss)\n",
    "            \n",
    "#             if i > 0 and i % 100 == 0:\n",
    "#                 val_acc, val_loss = test_model(val_loader, model)\n",
    "#                 val_ls += val_loss\n",
    "#                 print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format(\n",
    "#                     epoch+1, ep, i+1, len(train_loader), val_acc))\n",
    "    \n",
    "    val_acc  = test_model(val_loader, model)\n",
    "    print('Val Accuracy: {}'.format(val_acc))\n",
    "    \n",
    "    if plt:\n",
    "        plt.plot(train_ls)\n",
    "        plt.xlabel(\"n\")\n",
    "        plt.ylabel(\"Train Loss\")\n",
    "    \n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-gram (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 86.32\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 86.72\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.14\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 88.06\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 87.32\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 88.4\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 65.84\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 63.42\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 66.9\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 62.34\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 66.1\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 63.18\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.54\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 87.7\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 84.88\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 88.42\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 87.36\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 88.3\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 69.42\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 65.52\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 71.22\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 64.94\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 67.18\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 67.72\n"
     ]
    }
   ],
   "source": [
    "model_n1 = BagOfNgram(len(id2token_n1), emb_size)\n",
    "val_acc = train_proc(model_n1, train_loader_n1, val_loader_n1,  0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-gram (word) no tokenizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 86.12\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.94\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.1\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 88.06\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk,  0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 87.66\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 87.78\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 66.94\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk,  0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 61.2\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk,  0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 67.02\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 60.72\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 65.66\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 62.52\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 84.7\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk,  0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 87.06\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 84.84\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 87.12\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 86.78\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 87.88\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 69.16\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk,  0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 63.34\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk,  0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 71.2\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 65.3\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk,  0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 67.4\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk,  0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 66.32\n"
     ]
    }
   ],
   "source": [
    "model_n1_ntk = BagOfNgram(len(id2token_n1_ntk), emb_size)\n",
    "val_acc = train_proc(model_n1_ntk, train_loader_n1_ntk, val_loader_n1_ntk, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 83.54\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 83.6\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 83.46\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 84.84\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.08\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.3\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 55.98\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 55.0\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 60.6\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 53.74\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 56.6\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 57.28\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 82.98\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.04\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 82.6\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.68\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 84.72\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.38\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 54.34\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 52.54\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 52.6\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 59.56\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 57.06\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 60.64\n"
     ]
    }
   ],
   "source": [
    "model_n2 = BagOfNgram(len(id2token_n2), emb_size)\n",
    "val_acc = train_proc(model_n2, train_loader_n2, val_loader_n2, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-grams no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 83.04\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 84.06\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 83.22\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.1\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 84.84\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.24\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 51.96\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 52.1\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 58.16\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 53.18\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 56.0\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 55.6\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, True, 5, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 83.2\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 84.2\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 82.46\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 85.14\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 84.34\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 84.78\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 59.2\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 56.56\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 62.2\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 56.86\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 61.32\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 59.7\n"
     ]
    }
   ],
   "source": [
    "model_n2_ntk = BagOfNgram(len(id2token_n2_ntk), emb_size)\n",
    "val_acc = train_proc(model_n2_ntk, train_loader_n2_ntk, val_loader_n2_ntk, 0.01, True, 5, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 78.18\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 76.18\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 77.54\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 78.44\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 79.74\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 80.44\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.34\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.18\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 54.8\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.56\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 52.2\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 54.56\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 76.58\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 78.02\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 77.16\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 79.84\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 79.86\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 80.18\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.16\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 51.5\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.34\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.32\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.32\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 52.94\n"
     ]
    }
   ],
   "source": [
    "model_n3 = BagOfNgram(len(id2token_n3), emb_size)\n",
    "val_acc = train_proc(model_n3, train_loader_n3, val_loader_n3, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-grams no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 77.6\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 77.28\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 76.88\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 78.62\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 79.22\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 79.92\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.24\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.38\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.2\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 53.26\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 51.66\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 53.08\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 76.9\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 78.64\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 76.22\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 79.78\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 78.94\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 80.14\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 55.02\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.12\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 55.5\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.76\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.16\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 53.82\n"
     ]
    }
   ],
   "source": [
    "model_n3_ntk = BagOfNgram(len(id2token_n3_ntk), emb_size)\n",
    "val_acc = train_proc(model_n3_ntk, train_loader_n3_ntk, val_loader_n3_ntk, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 70.68\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 70.96\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 72.46\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 70.22\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 74.28\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 74.64\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.16\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 49.84\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.36\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.16\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.16\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.72\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 72.56\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 71.06\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 71.48\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 72.9\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 74.46\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 74.58\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.16\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.84\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.18\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 49.84\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.16\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 53.36\n"
     ]
    }
   ],
   "source": [
    "model_n4 = BagOfNgram(len(id2token_n4), emb_size)\n",
    "val_acc = train_proc(model_n4, train_loader_n4, val_loader_n4, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-grams no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 73.48\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 66.1\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 72.3\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 70.52\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 73.34\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 73.28\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.72\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.74\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.26\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 49.84\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 52.54\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 51.74\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 72.18\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 71.52\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.001, False, 3, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 72.0\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 72.4\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.001, False, 5, 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 72.84\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, True, 3, 'Adam', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 73.62\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, True, 3, 'Adam', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 49.88\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.18\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.001, False, 3, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.16\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.14\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.001, False, 5, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.16\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, True, 3, 'SGD', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 50.6\n"
     ]
    }
   ],
   "source": [
    "model_n4_ntk = BagOfNgram(len(id2token_n4_ntk), emb_size)\n",
    "val_acc = train_proc(model_n4_ntk, train_loader_n4_ntk, val_loader_n4_ntk, 0.01, True, 3, 'SGD', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary (result of the best model on test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_proc(model, train_loader, val_loader, test_loader, lr, adj, ep, optim, lr_decay=0, pl=False, pl_val=False):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if optim == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    \n",
    "    if adj:\n",
    "        scheduler = StepLR(optimizer, step_size=1, gamma=lr_decay)\n",
    "    \n",
    "    train_ls = []\n",
    "    val_ls = []\n",
    "    for epoch in range(ep):\n",
    "        if adj:\n",
    "            scheduler.step()\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_ls.append(loss)\n",
    "            \n",
    "            if i > 0 and i % 100 == 0:\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                val_ls.append(val_acc)\n",
    "#                 print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format(\n",
    "#                     epoch+1, ep, i+1, len(train_loader), val_acc))\n",
    "    \n",
    "    test_acc  = test_model(test_loader, model)\n",
    "    print('Test Accuracy: {}'.format(test_acc))\n",
    "    \n",
    "    if pl:\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(train_ls)\n",
    "        plt.xlabel(\"i\")\n",
    "        plt.ylabel(\"Train Loss\")\n",
    "    \n",
    "    if pl_val:\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(val_ls)\n",
    "        plt.xlabel(\"i\")\n",
    "        plt.ylabel(\"Val Accuracy\")\n",
    "        \n",
    "    \n",
    "    return test_acc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.48\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXecFdX1wL9nG0vvRRFZEFApCoiI\nvWGPYBejMTHWJMao0QR/JmpQE9REjbEFW+y9oaKIimJBcUFAOktf6kpbFrbv+f0x896+9/bV3dd2\n93w/n/d5M3fuzJw3M++eOefee46oKoZhGIbhISPVAhiGYRjphSkGwzAMww9TDIZhGIYfphgMwzAM\nP0wxGIZhGH6YYjAMwzD8MMVgGIZh+GGKwTAMw/DDFINhGIbhR1aqBYiVLl26aF5eXqrFMAzDaFTM\nnj37J1XtGk3dRqcY8vLyyM/PT7UYhmEYjQoRWRNtXXMlGYZhGH6YYjAMwzD8aHaK4dqX5vDgJ8tS\nLYZhGEba0uwUw/vzN/LgJ8tTLYZhGEba0ug6n+tLVXUN2/ZUpFoMwzCMtKfZWAz/nbGSkXd/Gvfj\nbtpZxs7Syrgf1zAMI1U0G8XQNjcxxtGof3zK0fd8lpBjG4ZhpIJmoxi6tGnht759d/zcSsVlVXE7\nlmEYRqppNorhtME9/NaH3TkN33zXO0sr2VNhDbxhGEazUQwiwm+O28+vrM8tUzjp/i8AOPhvH3PM\nvZ+nQDLDMIz0otkoBoAbTxpQp2z5lhLv8k8l5ckUxzAMIy1pVoohOzODDq2yE3LsknJzQxmG0TRo\nVooB4KyhPeuUVddokJqxMW/djgYfwzAMIx1odorhL2ccyISxg/zKtibIhVS4fY9fB7dhGEZjoNkp\nhqzMDHKzM/3KPluyxbtc34Y8cLfZa7Zx1D3TeT2/sF7HMwzDSBXNTjEAVFbXAJCT6fz88W/96N12\n9weL43KO5ZudTu38Ndvicrx0QFV5YNoy1u8oTbUohmEkkIQqBhE5VUSWikiBiIwPUecCEVkkIgtF\n5KVEyuPh7GE9OWdYT1644rA6257/NupcFmERcb6bkidp+ZYS/v3pcn7zwuxUi2IYRgJJWBA9EckE\nHgFOAgqB70Vksqou8qnTH7gFOFJVt4tIt0TJ40urnCzuv3AoRbvq9i1kZUhcziE4x2lCeoEaV8uV\nV9akWBLDMBJJIi2GkUCBqq5U1QrgFWBsQJ0rgUdUdTuAqm4hiXRpk1OnLCszPpekKVoMhmE0DxKp\nGHoC63zWC90yXwYAA0TkaxH5VkRODXYgEblKRPJFJL+oqChuAorUtQ4yg1gMH8zfyPerw/cVaIBt\n4Dl2UxyVFPhbDcNoWiRSMQTzyQS2KFlAf+A44CLgSRHpUGcn1UmqOkJVR3Tt2jXugvoSTDH87qU5\nnP/4zJiO4zlKU2pCJegtNQyjqZHIRD2FQC+f9X2ADUHqfKuqlcAqEVmKoyi+T6BcYfHtY5i1ahur\nt+6u13FqXUlNSTUYhtEcSKTF8D3QX0T6iEgOMA6YHFDnHeB4ABHpguNaWplAmSKycWeZd/mC/87k\nT2/MD1rvvqlLyA/jXspwNcM7czewq6xpJfIxXWcYTZuYFIM4tI6mrqpWAdcCU4HFwGuqulBEJojI\nGLfaVGCriCwCpgM3q+rWWGRqKCP7dIp5H1XlkekrOC+Me8m3++LhzwrqI5phGEZKiKgYROQ5EWkn\nIq2AhTgunxujObiqTlHVAaq6n6re7ZbdpqqT3WVV1RtVdaCqDlHVVxryY+rDa1cfzn5d/XVdTYTY\nSRXVdYdrhnuLropDLKZ0IkifvWEYTYhoLIYhqloMnAV8jNNX8KtECpVsVhT59yPMWbs9aL2pCzcB\nUFbhKAbf/ohLn57lN3LJd8STuV4Mw2hMRKMYckQkC2cOwjvunIQmPcPpwU+Wc+vbP9Yp/3TxZgBK\nK6sByMnyv3y+I5ea8ku1KTrDaNpEMyrpSWAtsAD4QkT2BUrC79K4+argJ74K0i0gCGu37uH+aUuB\n0LOk5xfu4Itl8ZtvkS6YC8kwmgcRLQZVfUBV91bVk9UZe7kOOCHxoqUfInDlc/m8M3eDux68pRzz\n8Ne8Mbs2qurTX69i3bY9jH3ka3bsqUiKrIZhGPUlms7na0Wknbv8X+A74OhEC5au+HY8x/IG/cj0\nAuat28GHCzYlQKrkYp4kw2jaRNPHcJWqFovIyTghLX4D3JtYsZLLH4Pkgg6GCPh6j4IFk6sMMmIJ\nUuuXLy6r5LZ3F1Dm9o3Ul2j1YFWIa2AYRuMgGsXgadJOA55R1dlR7tdo+P2J/aOsKd6Ja1DbCe1L\n/1s/DHuE6hqNSyrRWHjok+U8N3MNr8xa26DjRJL6wU+WkTf+A/rd+iHLN+9q0LkMw0gd0TTw80Rk\nCnAm8KGItKGZehNEgsdSigZP4Lm/vLOAM//zVch6NTXK9t3164eY8uNGVhTVHRcQbN5FQxDgv1+s\nIG/8B35zPh78ZLl3eX7hTj5asMmsB8NohESjGC4D7gBGquoeIBe4PJFCpTOhOpxjYdHG4pDbHv28\ngGF3TmPjzlLyxn/A7e8uiPq4v31xDif+64s65R4Lpb5KLRAF7pvqjMwKNXnvwwUbueaF2Uz6MqUR\nTgzDqAfRjEqqBroAfxKRicChqvpDwiVLQwSIU7qGkExb7KSk2OTGbHp2ZsMzynna7oYqNc/e23ZX\n1AYJDGE8bnGTIG3yiT1lGEbjIJpRSXcDf8IJbrcSuFlE7kq0YOnIq9+vY8H60G/74Zi+NLZ5DeF8\ndYfe/Qmn/ftLZiwr4vpXIuvomigthl1llVENp3UUgyffRIhzpuksuKWbdvHczNWpFqPRsmNPBXnj\nP2BGE5ynY9QSzfvvmcBoNyfCJOBkYEyEfRodo/pGDqbXkJhHwdKINuRYizcWc+nTs7xzKsJRraEV\nQ3lVtVdxHHLXJwydMC0qGTxHCqUAPMXpNifulAdncNu7C1MtRqNl4QbnxejxL1akWBIjkUTrGGkb\nYrnJ8PKVo1g8IWgCubQnUs4Hr8UQxJW0/18+4sbX5gJQURW+oziYJyqUrkxTg8EwjCiIRjHcC8wR\nkSdF5CkgH7gnsWIlHxGhRVb6jMKN5U07UiPssRg2Ffv7+z0KIxqrIxCPkghlMXjKA/s1issqWbrJ\nhrIaRjoTTefzC8BRwBT3cwwQnb+hkZERp1E78SCWF+5I/nzPqCTPSCIPuyuqvMt54z+ILJPPaTxp\nPjWK0agfLdjkDUB4+f++55QHZ1hmu0aK3bbmQVSvyKq6XlXfUtU3VXU9jtVgNIBPFm1mv/+bQkl5\nlV+5RzWd8+g3fuVbS8rZHVDXQ7iuj6rqmpAT6naXu1FiQwy1ev7bNeSN/yDoXASPDn1v/gYemV5Q\np6H3VVbXvDCby591Hpkf1u4AqPO7jcaFBVRs2tTXdxLVYyEip4rIUhEpEJHxYeqdJyIqIiPqKU+j\n4/5py6iuUVb/FF1O6UPu+oRTHpwRdFs4i6HfrR+GjM/kCd+REeIp+MeUxQCUuX0Pvo2Bx0X0l3cW\ncN/Upcwv3BkgE3X2AWib6wT03VnatNKdGkZTor6KIaJBKSKZwCM4oTQGAheJyMAg9doC1+EE5zPC\nULi9NGh5fYeGevYrCxLzCeqOLPJ3JfkTGIfJY0FIQM0WWZlA5I5uwzBSR8h8DCLyAMEVgADtozj2\nSKBAVVe6x3sFJ9nPooB6d+J0cN8UjcBNhXi6Umat2saheXWH20ZKURpq+O3STbso2FLinbxWH7eB\nhrAYPC6oZMeLMhLDe/M28NHCTTzy8+GpFsWII+ES9YSLxRBNzueeOLkbPBQCh/lWEJFhQC9VfV9E\nmpViWLttT9Dyuet2RH0MEacB/tUz33PKoO7e8tP//SWXH9WHUwf3CLt/qMbZ47LyjNLyNPJ+tSMo\ni2BHnjRjBRvcmdDV1ouZVCqra/h8aREnDeweuXIM/P5lZ4LlIz+P62GNFBPSlaSqT4X7RHHsYE2H\ntzUQkQzgAeCPEQ8kcpWI5ItIflFRYmdcLr/7NPp1a5PQc/hSXFbJHZMX1isktu8FXr65Nnjeoo3F\n/PH1eSFDgHuI9NauPt+T521g7tpapZURwYyodSXV8vcpS6I+d6JpbqOi/v3Jcq58Lr9JZhY04k80\nqT3rSyHQy2d9H8B3wHxbYDDwuduR2QOYLCJjVNVv1JM743oSwIgRIxL6j87OzKBHu1wKtiQne+kD\n05bx/ert/O+b1fTs0DKmfcVjMhDc3ROs7Xstfx17tc/l6P5do26cVZXrXvYPvRF4vsAjRTpy6hVD\n8xpZs267Y6HGGrn35VlrefyLFXxx8/GJEMtIUxI5o+t7oL+I9BGRHGAcMNmzUVV3qmoXVc1T1Tzg\nW6COUkgFD100LGnn8u2EXb8jeOfyxwuDjyrybVyDBcgL1vT+6Y35/OKpWUAUIT7czcGqBZ7t3bnr\n/XcN0cfgIeWKIaVnj47qGuWej5bUOwy7L/U1kG5560fWbA3u9jSaLglTDKpaBVwLTAUWA6+p6kIR\nmSAiaR1rqVPrnKSda17AMM9gXPX87Ih1gs3NCzdaadqizZz1yNdhj+mNnBpFo/LyrHV+655zV1YH\n3zmZiuHSp2fx2vf+8jUGV9Knizfz2OcruH1y/GI7NScryag/EV1JItIF+DWQ51tfVa+KtK+qemZL\n+5bdFqLucZGOl07ce+5B/OnN+akWw0vgsFAI/5b4wLRlEY9Z2+lc90CRQnh79v3fN6uDbk+mYpix\nrIgZy4q44NBekSsD901dQoYIfzx5/wRLFh7PNbKhvUayicZieBfoDnwFfOrzadacefDeqRbBj+B9\nDKEb32iS9nj2DtaGR9o9UjTZeCiG6hplcZikR+EId/ZHpq/gP58V1E+oOJL+Nk0t6WiBlZRXhXTP\nGuGJpvO5tapGHDnU3GgMJnmwnNQeflwf2YXl+bMH/9OHvwCR0onGY7jqQ58u59+fLmfKdUczcO92\nMe2bhu1YWqOqYa3EdOzMP/uRr1m+pYTVE89ItSiNjmgshg9F5OSES5JmdGvbIuz2SMM1k82SIBFL\nvyr4qUHH1IBvXxr686uqlY8WbIw4CS8c8wqd4bObimN/KwyVec4ITiRFGqw/a09FFV838BlsCMuT\nNLKwKRKNYrgG+EhESkRkm4hsF5FtiRYs1URq+NMoEGtIWmZnNmh/z3892J++oT//xe/Wcs0Lc3j5\n+7X1PkawUB3R4rvPm7MLOXLiZ2npDoH0eBOPOPw4yLW7+Y35XPzkd6wLMZnTSF+iUQxdgGycMBhd\n3fWuiRQqHWiVE75RTZXFsHBDZBeQh4YqBi8JaC8L3XH1nr6IXWWVPPP1qpgaZ889aGh7fvMb81i/\nozRslNpUkg76KtJ9CbZ5+WbHit1TEfvkTSO1hFQMItLfXRwU4tOkeeayQ7l+dP+Q21P1FndHDEMX\n45VfYkEMyihaPLOyPVnl7pi8iL+9t4ivC7ZGfYxIyYJiJV0thnQg0pUJdg98i25560e+Wp46t5IR\nG+EsBk+Y7EeCfB5OsFwpp3fn1lw/eoB3/Yqj+vhtjzRcM1F8v3p71HWvjmL+QzT8sLZu/KaGNqEr\nipxw4x7ltX2PM4mrvCqWt0uptyy+jVa40VfpQDwetYb+tMChy4EKPNi18xSJODOoL3nKAig3FsLF\nSrrc/T46yOeY5ImYHvzlZ3UihjP1+uZxGTwJfXyJNBw1WjyNnje2UgyNYO2+sZ83WOdzOnVIb9hR\nGtXIsWQR6drMXbuDvPEf+OUXCRYvy2gcRDXzWUQOEJFzROTnnk+iBUsXRgYJZ+2hb9fWSZQkdTz9\n9aqEHTuzAa/DtXvG3qAHUybp5Ek6YuJnPPb5ilSL4aWkrIo/vTGPkrLg4eJfn+3MLP986ZY622K9\nxYfcOY1/fbw0ckUjYURUDCLyF5wAdo/jJN15EDgvwXKlDa9dc3jIcdDZmRms/Pvp3lDGB+4V21h6\nw6cDuSH71mPngi0l5I3/gOdmrvaWxVMxLN20q0n1WTz11Speyy9k0pcrg24P50qKla27K9JigmFz\nJhqL4ULgeGCjqv4COJjERmVNe9793ZHe5YwMYWivDgDkZCUyJmHTxDPKqjZbXPDXy+lLt7CluMyv\nsfW8idZn1MtYN07UXR8s9pbFqxN71qptnPLgDJ6buSYux6sPSzftYnNxWdyOVx3BLRR0PkptkP24\nyWEkh2haslJVrQaq3DScm4C+iRUrvTnYVQQe0mGceWPlnblOJPZwbUhxWSWXPfM9I//+qd+b5DJ3\nOOQfX58XVSMYzD3hm7MimFqoz1u/x8++IIV9BKc8OIPD/h6/yDWeyxBqmLYnxInvoAwNsmTETkVV\nDWc89GVSJwtGoxh+EJEOwNNAPjALmJNQqQzDB/WJrvHWnELvsmdkE8Bhf/+URRvCx00K5p5QDT2R\n76MFm+hzyxRWFMU2g7Ymyo703eVVzF7TOOaKbi1xRo35Kgbf9LTBh6sGVwgl5VV8tMA/lHxNjfLf\nL1ak/WQ4VeXJL1eys7QyaefcuLOUhRuKueWtH5N2zrCKQRz1f4eq7lDVR4AzgKtV9dKkSNdI8Lg/\nendqFbZepElzzZWlm3Yxc4XzNiRAVXUNG3aUMm3RZkorqhGfpzTc3IzJ82rzQL3zw3q+Xx1bo6sB\n4Z0++HEjUP83/1BuMQ9/eGUu5z42M2K+hVBGS1lldZ0GNh68MbuQvPEf+GUVfNOjkH1+0l/fqc3+\n6/EkbQpiuQXKf9Nr87jmhdms9FG4cwt38I8Pl/BoGnW4B2Pmiq3c9cFibns3XObj+JKKrqqwikEd\nlf++z3qBqpq1EMCxA5yJ4L88Ii9svdYtmnXXTEhOeXCGN2+DiPD3KUs4YuJnXPlcPrdPXuD3xwg3\n49x3DsT1r87l/MdnRuUK8g57DXB51L75157zkekFzFoVXuEEO+OOPRWMf3M+8wtr54R4FM6zM1fz\n6eLNIY/3UYhETXdMXsg1L8xmnk+e8N3lVV4XG8D0JXVHCUXiftflti2IwvLVy2//UJucyXOtfEdS\nhYq1tcp1tfkGWiyvdJZjtc4WbyzmyufyI6axjZXd5VVUBTmmpz9rV4jRWYkkmS7raFxJs0RkeMIl\nacQM3LsdqyeewSG9O4atZxZDZGpqlC+W1TZmr+UX+jWm4Ya3lgfJWxDN21atKymw3CnwNIZ54z/g\nvqlLueC/M6M63ozltfmV/z5lMa98v44xDzud3sVlld636wc/Wc7lz8aeuHCt63bxdelc/fxsTn5g\nhnf9sv99H9Wxzn3sGw66YypvzSmkssbzu+te61BWULAw6h5lEehm8nRkN2Sosoeb35jHtEWbWbKx\nbhDJhjDo9qn8PiCdLdT+lmhD4qiq3/PbWAgXEsPzensUjnJYKiJzROQHEWmWVsMdZw7k5StHha3z\nxjWH849zhgTd1irHLIZIXPa/7/36DsBJZO8hnCvppe/WsnOPv+83Fis80LrwvB0+MWMlQ+6YGrCt\nys/V4n9O5zgbd9a6VXwz2dXUKNe/MjcGyRxG3/8Fo+//IojctcvBIuo+P3M1783bUKfcl9lrtlNc\nVsWNr83zTl4M1vaFag99G/9dZZV+ctUE6GvPCKag9zLKGxavocA1NcoPa4NHE/gwiJvOo/8yBOYX\n7uC7leFDuLw0ay1jHv66XpZbKglnMcxyv88C9gdOB87HmcNwfjQHF5FTXYVSICLjg2y/UUQWich8\nEflURHrHKH9S+dWRfTh8v85h64zI68TZw3oG3dbaLIZ64dsYRQr/9EpAtNZYGpDAl97Plzpv/PMK\nd9ZxHQy8bSon/qtuI+2cM/x5qlVZvXV3nfJQisZDwZYSCtxQ0j+VlEedhOav79YvNWiwSx3qTdlX\nMQy542PeCeJm8uDJNR7MYohmyPCarbvpc8sU3pu3IUqLMHSlx2es4OxHv4nYwAfKlyHCmIe/5sJJ\n33q37Syt5L6pS/xcUMvccPjB7ne0pGJMVzjFIACquiLYJ9KBRSQTJ67SacBA4CIRCYwr8QMwQlUP\nAt4A7q3Xr0gzQr1VZWQILWyuQ8z4xodauKGYuet2eKOzRiImiyHGv2CohjliiOoaDVrpgL9+FPW5\nR9z1CWu2Otdg1uptPBli4lkgscxtCJaWNaTFEGAVXP/qXG+jHehmqg7iqvI03vlr6r69X/fyD4yb\nVOu+82Tt87WCwnl2/OJiqfLtyq3e8y10R7JtjiLEy4L1O73WVLAMiBM/XMwj01fw4YJNFJdV8tsX\nZ7N9T/1HL33440a/+5rMUfHhfBtdReTGUBtV9f4Ixx4JFKjqSgAReQUYCyzyOcZ0n/rfApdElLgR\nEOqtSlU5un9XPgnT0Zgu/GJUb57/NnUTtMIx/s35QRMTAawJGO4Yi8chbqM/fA5UVlnNvz5e6ueu\nuPmN+OYKf+hTx9V2xdGRpxf9fcoSrjpmv6iOG2yEUKjgkeEy8gVaAZ712oB8P4XN+Dc5wA3mkSHQ\nwttSXMaE9xdx33kH09LHOvetNnXhJq55YQ53njWYX4zq7XVrTXhvEWMipOv92X++8pGh7nZPB3pV\nTQ3Pz1zDlB9rXVHRNurbdlcw/M5p3HnWYO+or8B5U8kg3OtrJtAGaBviE4mewDqf9UK3LBSXAx9G\ncdy0Jzszg9t+NpB2uY7e9eSHdp7ByK1PbnbqrYrj9q+bcqNtmoyqCteAv/Td2oBJa9G39g1RDKUV\n1dw/bRn/mLKYZ31mPE94fxFPfLmK1VtrFdZ78zaElGprSTnFZeHfMuMdaiOWET0zlhUFLQ8289kj\nZ+CgAI/FULi9lNlrtnPxk99x30d1Jx/W1Ch54z+oU1774qV+92ziR0t4f/5G3p/vr0h8FZPHylrr\nunY8svxUUmsxRHN9g1kMxa670ZkbU797tHGnY4U+Nr12zs35j4cf7JAIwrVAG1V1gqr+LdgnimMH\nU5JBr5aIXAKMAO4Lsf0qEckXkfyiouAPZrrx66P6sF+3NgCMzHNGK3VsleP3IN951uCg+54zfJ+E\ny+dLsFAewZL8dGqTkwxxIrJmW3h/7R6faLCx/D9rVCMORQ3Fo58X8NCny/nvjJXefgBwFFUwVv0U\n/DccctcnXBFhhJJvR7Yv9UmT+tGCTfS/teHvY1Vhzj3Oxw8PtQ31xU9+522QF22sOzkx0Ap57PMV\nVFTVePuZAl1UEiIM+5fLi7z9N94RURkZfrL4nTeK6xjoFfh44SavJ0C1/iHcczIduTbsrOvyS2ao\n/4h9DA2gEOjls74PUGdohIiMBm4FxqhqUEefqk5S1RGqOqJr18aTPO4It6P62AHd+PvZQ/jn+Qf5\nPbTd27bg2uP71dkv3mlDh+8b3hQNdrqWAR3lt585MG3yXJdVhn/D/XRJravOd6x9JD5asCniUNRQ\nlMYxS1kk5RRsfgFEHwV34odLmPLjRpZt3sW0RfFxa1YFdjIQ/C3w0c8L/BrecI2wZ7a1h3s+WsLT\nX6/yPofTlxb5KZRQj+ev/5fvTXBVXe1RDMHPX1FV4xco8IZXg48eC5z06Ns38sfX54X9Xd+u3Mra\nrXX7yOas3Z7S+Fq+hFMMJzbw2N8D/UWkj4jkAOOAyb4VRGQY8F8cpdC4xnNFwY0n7c8XNx/Hvp1b\n8fPD9qVDqxzO9bEGsrMyOHVwjzr7qUKPdrkxny/UaKho3zSO6tfFu5wbYDGcM3yfBr0pHN2/S+RK\nceLG1+Z5l2MJI7A2zcMxeFgXouN9cZRj+R//YgW/fXEOJz8wo3ZGcwMJ5o0KZq3d+9FSP+tiVxi3\n2ah/1I31tKusMuJEr/Fv1u3D8UycC5xDEWjpPPnVSu71cWu9HWIG/fIt/hPx2gS4WUO55xas38m4\nSd9yzH3T62w759Fv0qZfL1yingYFcVHVKuBaYCqwGHhNVReKyAQRGeNWuw+nH+N1EZkrIpNDHK5R\nkpkh9O7sn7PhjIP28jaSLTIzgj5Avg/+MJ+3/XAT6E4b3IMHLhzKgxcOrbMtkr/z6mOcTsvjD+jm\nLWub6/+gZ2dKSBvyuhPqWj0AE8Y2rgyw9Ymu+sSMlRxz73S/OQuJZnd58Fm3y7fEd5JXLCyOwhXk\nwbfPIZwLKhizVm3jV88En7TneTxrgvj4PacJnEPxpU+60c+Xbgk6o/n8x2eG7FsBZ+Jj4LOzsqiu\nq/Drgp/8OrA9lFVW+01STAcS2supqlNUdYCq7qeqd7tlt6nqZHd5tKp2V9Wh7mdM+CM2DSaeexC/\nOiKPkX06eU3O/XyS/tx40v7e5b07tPQuv/mbI8jr7MRjuiugfyLbtY2Dza4etHf7sPLcePL+rJ54\nBlnun6VLmxZ0D7BYsjIyKCp2PH2XB6Q5HRZCYTW2dAT1UQx3T1nM2m17vHGVEoVvyIxgGfUA5hem\nT8Y3CP1CUuGjGGLtFwmX2rZwe+3w4UBXzuw123liRm3wu+27K9iyy1+ZX/387JBW8aVPzwqxxWH9\ndv+hy4FhTJTgcxlW/bSbA/76EYNvn1pnWypJ/fCXZkjPDi25Y8wgsjIzvG9MbXKzAafzqVPr2k7e\nP52yP5cdmcenfzwWqH3zObp/F1ZPPIP7zjsIgKxM55EOHC1xZL/OjBlaOwzvZwftFVG+04f0qNOf\nkJUhnHuI4wY7M3BYX4j/tn/uhPTonwjHOz+Enx2cSnxDZoSyGNKNUJ3kvhSVhA8gGC0iMNNnklow\nfXO3z4ixZ2euYeTd/q6qhsRb2hFFtNXA7HdfLi/i+H9+HvU5PHnRk4EphhTTy43IesYQt68hoP3M\nzszg9jMHsV9XZ4STJ1Bf5zYtgNo/n2c0w7EDuvKrI/K87p08H1dWv25teCCIq8mDx7zOEPHrAJ8w\ndhAZGcLtZw5kyZ2n1tkvdJiE2mWPkrh+dH9+H8L1lGrSzZwPRTJDPjeEaOT0zMFoKOc95j9ooD7W\nX31HEgERO/FXFu3mHx8u8Sv7xVPhrZBAduyprGPlJIr0GJjejOnZoSWLJpxCy+xMpi8p4spj+oSt\nf/lRffxcOZ7RFZ7Or6zMDO4YM4hdZZUs2FDM70/o7+1U7dAy2+tyAnju1yP90pGef8g+LN+8ixtO\nGuD3hn/p4XmA89afm53pnfIBWPBiAAAgAElEQVTfp0trThvcg6P7Bx8p5vvn9Jj2e7XPpaXFjGoQ\nd09ZHLlSM6M0IJxINENOg5EfxlXVEL5eEZ8kO49OX8EdYxLfd2cWQxrQKicLEeHlq0ZxwgFO/uhj\nBjgd1K0jNKJnD9uHa4/vxw0nDfArb5ubzdO/OpQe7Wv7CgLf7I/s14WubVt413OzM5kwdjDtW2aH\nPafHSunWtgV/OvUAMjOEJy8dwTXHhp5R683whXDmQXv5jc4yjHgzqJ4++1kx5vCIlmCd0fUhcBh5\nojDFkKbcddYQZtx8PO1bhW+kc7IyuOmU/euV66G+8yU8CqadjwIZPbA74087wK+erzV/7Qn9GNG7\nI6cM7oGIcNUxzTo7rGHUi+x4T3IKgSmGNCUnK4N9O4fPCBctHqvgkN6d/Mqj6RDu6TMqysPIvE5c\nP7o/95x7UNh9fcNR9OzQkjd+c4TXGukcp1nUqyeeEXXd9649Ki7nNIxUkaxBHObsbQb06dKaT248\n1jvUNVpev+Zwv85rDxkZwvWjBwTZo5aeHVr6deYFWjRd2rTgh7+exLA7p/mV79+9LUs3x388/skD\nu9O3a93fYhiNiWQN7jOLoZnQr1sbsjJju92H5nXy64OIBs/kvTd+c7h3ktxpg3vUmRcB0LF1Xavh\n/BGx9z08cOHBEetU12hc/lTnDA8XBzK+XHdi/6SdKx3497ihfHzDMakWI60JnGGdKMxiMOLKc78e\niapjVYw7dF+qqpWLRu4b9f7hRpNcfNi+vOgTlO6MIc6cjLOH7cMNr84LtRvgzLCNR6yn+y8Yyltz\noo+/1BCaW+6OXp1aMaB7NIGbmy+eEYKJpnk9eUbCERHvfIjMDOGXR+QFjd7q4bIj8/zWA0MkXO3T\nST2yTyd+dURt/UhDEn0nCsbLYoiGXp3q9svUh6wMYd9O8elnSiTzbjs5LsfJzrDmKBLh/kvxxO6E\nkVL+esZA/ugz1PaikftyxH6d+faWE3ni0hGMP+0APr/pOP540gB+dpD/jGvfOR+TfnEIU6+vdUNc\nMGIfplx3NDe6x66srvGGZRaBOX89KWZZA5VYKC4+LPYMtf+5aFidsvMO2cfPtTLQZ85JLHQIMbJt\nr/bhAzUe0KMt/dzQ8YE8fslw73KkkXPRkp2V/rPjAzmwnvck3THF0AyZdsMx3lAaqSYjQ/j9if2Z\nftNxzPq/E+nUOoeXrhxFj/a5nDSwOyJCXpfW/P7E/mRmiHd+x9u/PcJvlNXJg3owoHttI3bveQfT\no30uo/o6oc99LYZ9OrakU+scHr/kELq1bcFLVx4W1rc9uGc7Lhq5L9ed4O/z7x+k0Xz+8pFh53P4\nMubgvbnuhH4886tD60Sf7dOlNZ3btCA3O5MRbiyqKX84us4xgg0oGHdoL7/1j68P/tsO6BHebTNw\n73b0DmGxnDo4fGiVq4/ty7/HhZ5l78uxA5wJkh1aOhbeLw9P69TvfoS6PvHg3d8dmbBjR8IUQzOk\nf/e2nD+iV+SKSaRPl9Z0iyLU+AkHdGfRhFMYtm/dwH0iwjXH7sfr1xzuLfPEkKqqUbIzM/j3uKG8\ndrWz/dTBPZh162iO2K8LA7q3Ddmg53VuzT/OGeLtLL/5FCfIYZc2dTvmPaFLgjHluqP5xSin0Zt4\nzhAeumgYN568P8cf0I0WWc7EJc8bum/MqxeuOIzvbx0N1LoSurZtwT/PP5gXrjjMz/oZfWA37jxr\nMJ/ceIwrT+jr+tBFw5gwdlDQnCAe7j57CBcf5t9HNDLPUcihUk7mZmdwy2kHMnZobUf9X38WmO7d\n4cs/Hc//LjuUmbec4J2MefKguqHoE81B+4QPNBmKTm1yePGKw4Ju6xjGknrpytp9RvgEoVw8oTbk\nzMG9OrDkzlOTGrLegykGo9HRKsxs8PGnHcChebWWRKdWTmPusSbGDu3JXu2D9wGMP+0Avrj5uDrl\nd471j2TryQ189rCedVKgetwzH99wDB/fcIzfn37g3u2YMHYQqyeewbiADvmWOZl8cuOxPPfrkQCc\nPqT2jTw3O9M7OmzebSez5M5T+f7W0Zx3yD7s07EVnVrneNOu3nfewWRnZngzlHn6bH4I4jprm5vN\npYfncdMp+9fZBlBcWkWP9rncffYQv/KHL3bcXi9ecRifucEdv/rz8Uy+9kjuPGsw7/++7nyRy3z6\nhnzp1akVIuJ3T470yQty4F7t/PqVAgnXbzTu0F7cG6Vl3K1tLh9c5y/3YxcPD1G7lltOO8BPXl9+\nCNH3cuXRfWiXW6s0nnXvOThK9d/jhnpddbnZmd7sc8nEFIPRpMnr0prXrzmcCWODp1ENpHfn1nVc\nIIHDant1asWSO0/lgkN78b/LRnKGG7H23nMP8k5AGtC9LQO6t+Xpyw712zfcBKV+3dqwd4eWzLvt\nZK4PMVS1ZU5mnSRKAH8bO4jTh/Tw9ie0dkMneBI+dWydw11nDfZOWLwtxBu8L76Jn0b07kjfLq15\n9apRdGvrHLNNiyz6uhbSPh1bcdA+HfjFqN7061brovrsj8fyv8sOJSND/N6S5952Eqv+cXrIc3vk\nfOs3R/DHkweEjAr8xC9GADB26N6snngGU66rdbdNPPcgLohgGT/9K2f/UwZ19waiBCcfSah8Epcf\n1YeZt5zA6oln0DY3fP/K9JuO444z/a+1r0wH7tXOb46PiDB2aE8/V91dZ/kr5mRgw1WNJo+vBREN\nY4f2pG+XNqwoKuGsEFnxfBvnf51/MJcdkceIIOdpF6HhCEZ9OnPPGb6PX67wbu1yefjnwzjc7WMB\nuGRUb5Zv3sWzM9dwWF9/WR+/5BCueWG2d71z6xyvwgN44zdHxCwTQN+ubbzK44j9uvC3MYN4LX8d\nHVqFn/n+1m+PYOaKrW5soEwe/vlw9u++nH9NW+at45n1/s34E7x5Swbu3Y6XrxxFlyAz67u1bcHt\nZw4iO1N4Y3YhHy/azAkHdGfxhFNpmVMbHBLgxztO4d25zrDkw/t2ZvueCpZsciZeXn1sX69yjESf\nLq1ZscW/H6JlTqY3kq/HNfjghUNDjmbb3+0Lqk9Wx3qjqo3qc8ghh6hhNCaWbCzWgi27Ui2GqqqW\nVVbp18uLgm77puAnPfzvn+iuskqtqalJsmTRsXbrbu395/f1uZmro97n8c8LtPef39eZK37yltXU\n1Gh1dd3f2P//pmjvP7/vd64Zy7aoqurWknL9YP6GoOfYU16lxaUVumRjsd71/kK99qU5ftt+8dR3\nWrBll27aWaqqqrvKKnX4hI/1qxD3IpBVRSW6Y3dFdD84BEC+RtnOiiYwzZaInAr8G8gEnlTViQHb\nWwDPAYcAW4ELVXV1uGOOGDFC8/Pzw1UxDKMJs6eiipbZmVHHDVJVlm0u8b55h2PDjlI27CgNav01\ndkRktqqOiKZuwvoYRCQTeAQ4DRgIXCQigY7Ny4HtqtoPeAC4J1HyGIbRNPCEqY8WEYlKKYCTSrcp\nKoVYSWTn80igQFVXqmoF8AowNqDOWOBZd/kN4ERpDDkgDcMwmjCJVAw9gXU+64VuWdA6qloF7AQ6\nB9RBRK4SkXwRyS8qKkqQuIZhGAYkdlRSsDf/wA6NaOqgqpOASQAiUiQia+opUxcgPjn2EofJ2HDS\nXT5IfxnTXT4wGWMl6inliVQMhYDvIOJ9gA0h6hSKSBbQHgibW09VgycYjgIRyY+28yVVmIwNJ93l\ng/SXMd3lA5MxkSTSlfQ90F9E+ohIDjAOmBxQZzLwS3f5POAzTeQwKcMwDCMiCbMYVLVKRK4FpuIM\nV31aVReKyASc8bSTgaeA50WkAMdSGJcoeQzDMIzoSOjMZ1WdAkwJKLvNZ7kMOD+RMgQwKYnnqi8m\nY8NJd/kg/WVMd/nAZEwYCZ3gZhiGYTQ+LIieYRiG4YcpBsMwDMOPZqMYRORUEVkqIgUiMj5FMvQS\nkekislhEForIH9zyO0RkvYjMdT+n++xziyvzUhE5JUlyrhaRH11Z8t2yTiIyTUSWu98d3XIRkYdc\nGeeLSOQg9g2TbX+f6zRXRIpF5PpUX0MReVpEtojIAp+ymK+ZiPzSrb9cRH4Z7FxxlvE+EVniyvG2\niHRwy/NEpNTnej7us88h7vNR4P6OuEQrCCFfzPc1kf/1EDK+6iPfahGZ65Yn/RrGjWij7TXmD86o\nqBVAXyAHmAcMTIEcewHD3eW2wDKcOFJ3ADcFqT/QlbUF0Mf9DZlJkHM10CWg7F5gvLs8HrjHXT4d\n+BBnsuIo4Lsk39dNOBN3UnoNgWOA4cCC+l4zoBOw0v3u6C53TLCMJwNZ7vI9PjLm+dYLOM4s4HBX\n/g+B0xIoX0z3NdH/9WAyBmz/F3Bbqq5hvD7NxWKIJm5TwlHVjao6x13eBSymbpgQX8YCr6hquaqu\nAgpwfksq8I1r9Sxwlk/5c+rwLdBBRMInBI4fJwIrVDXcTPikXENVnUHdyZmxXrNTgGmquk1VtwPT\ngFOJE8FkVNWP1QlHA/AtzkTUkLhytlPVmeq0cM/5/K64yxeGUPc1of/1cDK6b/0XAC+HO0Yir2G8\naC6KIZq4TUlFRPKAYcB3btG1rjn/tMflQOrkVuBjEZktIle5Zd1VdSM4Cg7olmIZwZn34vsnTKdr\nCLFfs1Q/p7/GeXv10EdEfhCRL0TEkxqtpyuXh2TIGMt9TeU1PBrYrKrLfcrS5RrGRHNRDFHFZEoW\nItIGeBO4XlWLgceA/YChwEYccxRSJ/eRqjocJ2T670TkmDB1UyKjOLPpxwCvu0Xpdg3DEUqmlMkq\nIrcCVcCLbtFGYF9VHQbcCLwkIu1SIGOs9zWV9/si/F9U0uUaxkxzUQzRxG1KCiKSjaMUXlTVtwBU\ndbOqVqtqDfAEta6OlMitqhvc7y3A2648mz0uIvd7SyplxFFac1R1sytrWl1Dl1ivWUpkdTu5fwZc\n7Lo2cF00W93l2Th++wGujL7upoTKWI/7mqprmAWcA7zqKUuXa1gfmotiiCZuU8JxfZBPAYtV9X6f\ncl+f/NmAZ8TDZGCciLQQkT5Af5xOq0TK2FpE2nqWcTonF+Af1+qXwLs+Ml7qjrQZBez0uE8SjN/b\nWTpdQx9ivWZTgZNFpKPrMjnZLUsY4mRZ/DMwRlX3+JR3FSfZFiLSF+e6rXTl3CUio9zn+VKf35UI\n+WK9r6n6r48Glqiq10WULtewXqS69ztZH5yRIMtwtPatKZLhKByTcT4w1/2cDjwP/OiWTwb28tnn\nVlfmpSRh5ALOaI557meh51rh5Mn4FFjufndyywUnU98K9zeMSIKMrXBSwbb3KUvpNcRRUhuBSpw3\nwsvrc81w/PwF7ueyJMhYgOOT9zyPj7t1z3Xv/zxgDnCmz3FG4DTQK4CHcSMoJEi+mO9rIv/rwWR0\ny/8HXBNQN+nXMF4fC4lhGIZh+NFcXEmGYRhGlJhiMAzDMPwwxWAYhmH4kdB8DImgS5cumpeXl2ox\nDMMwGhWzZ8/+SaNMjdzoFENeXh75+fmpFsMwDKNRISLhQsf4Ya4kwzAMw49GZzEYhmEkA2dMfxyO\nA1TXKNU1SlVNjfuttd/Vdcsrq4PUq6lhQPe27NOxVcOFikDSFIOI3ABcgXOdfgQuA44E7sOxXEqA\nX6lqQbJkMpoGqsruimqKSyspLqtk555Kisuq2Flaya6ySgTIzMwgK0OcT6aQmeGsZ7plzncGWZn+\n65lu/QwRKqpqKK+qpryqxvlUVlPmfnvKyrzL1ZRX1tbzlFVWKy2zM2ndIovWLTJplZNFG/e7dQu3\nPCeLVjmeOlm0zsmkVYssWmVnkpFRN8xOZXUNe8qr2V1RxZ6KKnaXV7O7vIrdFdXsqaiipLzKZ3u1\nu+5sV1W6tGlB17Yt6NbW+e7aNte7nJudmZT7V1Lu3K/qGqVFViYtsjLIzc4kJ8u5B/GgvKqa7bsr\n2bq73Oe7gm27K9i2pyJgWwU79lRQVZNe87zuOmswl4zqnfDzJEUxiEhP4DqcuOilIvIazlT1/wPG\nqupiEfkt8BfgV8mQyUhPVJVNxWWsLNrN1t0V7CytdBp8t9EvLnUaEGe50l2uojrN/sAtsjKcT3Zt\nI9ciy1FGGyurnca7wmmwK6proj5uqxxHibTIynCUQEU1FVXR7+8oJY8icv7+8wp3srWknGCXsG1u\nFt3atqBb21w/5dGtXQu6tsl1v1vQMiezVjGXOvepdtlV1Hvc++ZTx6O8w92+7EzxKgtfheG5ts4n\nk9xs57tFdgbllTVs213Otj2VbHMb+5LyqqDHF4EOLbPp1DqHTq1zyOvSiuG9O9CxVQ4tsuKjGDMz\nICsz8GXEZz0zdLn3BSVD6NmxZVzkiUQyXUlZQEsRqcQJabABx3po525vT5oFkjISR1V1DWu37aFg\nSwkFRSUUbClhxZYSVhTtDvoHzsnMoF3LbNq3zKJdy2w6tsohr3Nr2rXMon3LbNrlZrvbPctOeZsW\nWYhIraleXWuaV9XU+K3XMfWr/ctb+DVGnga/tjHybbxiSchVUVVDaUU1JRW1b/K7y6vYXe7zhh9g\nCVRU1dRaFa5F0TrH3xJp7WOFeBRKqLfvquoatu2pYEtxOUUl5RQVl7NlVxlFu8rZsqucol3lzF23\ngy27yiirjF4RecjNzvC7T93a5tKva1ade5aVkUFFtY/lVelrpVVTFsQKKymv4qeSCh8rrZqczAw6\ntcmhY6sc+nRuRcfWOXRunVP73SqHzu72Dq1y4maVNBWSohhUdb2I/BNYC5QCH6vqxyJyBTBFREqB\nYpxsVkYTorSimhVFJaxwG3/PZ/XW3VRW174mdm/Xgn7d2nDu8J7069aG/bq2oVu7Ft6GJBkujVSR\nk5VBTlYG7Vtlp0yGrMwMurXNpVvb3LD1PG4fX4WxZVc5ZZXVTgPfMpt2uVne5fYts2mbmxW3N28j\nOSTLldQRJ4tSH2AH8LqIXIITpvZ0Vf1ORG4G7sfphwjc/yrgKoB99903GSIb9aCmRvl40SbyV2/3\nWgHrd5R6O/AyBHp3bs1+Xdtw4oHd6detDf26taFv19a0y01do2hEj4jQNjebtrnZ9O3aJtXiGAki\nWa6k0cAqVS0CEJG3cDqeD1ZVTwazV4GPgu2sqpOASQAjRoxIL2eyAcDsNduZ8N5C5hXuJDc7g75d\n2jB8345cMKIX+3V1FEBel1b25mgYjYBkKYa1wCgRaYXjSjoRyAfOF5EBqroMOAknB7LRiNi4s5SJ\nHy7h3bkb6N6uBfdfcDBjh/Y0n61hNGKS1cfwnYi8gROTvAr4AccCKATeFJEaYDtOLHqjEVBaUc2k\nGSt57IsCahSuPb4fvzluP+9IF8MwGi9J+xer6u3A7QHFb7sfo5Ggqrw3fyMTpyxmw84yzhiyF+NP\nO4BenRI/6cYwjORgr3dG1PxYuJO/vbeQ/DXbGbhXOx64cCiH9e2carEMw4gzphiMiGzZVcZ9Hy3l\njTmFdG6dw8RzhnD+iF7Wj2AYTRRTDEZIyquqefqr1Tz82XIqqmu48ui+XHtCPxtaahhNHFMMRh1U\nlakLN/P3KYtZu20Pow/szq1nHEifLq1TLZphGEnAFIPhx+KNxUx4bxEzV25lQPc2PH/5SI7uH1Vu\nD8MwmggxKQYRuRZ4UVW3J0geI0Vs213Bvz5eysuz1tKuZTYTxg7i5yP3JSvTUnYYRnMjVouhB/C9\niMwBngamqsYjYrmRKnaWVvLUlyt5+uvVlFZWc+nheVw/uj8dWuWkWjTDMFJETIpBVf8iIn8FTsbJ\np/CwG0L7KVVdkQgBjcRQUl7FM1+t4okvV1JcVsVpg3tw40kD6N+9bapFMwwjxcTcx6CqKiKbgE04\ns5g7Am+IyDRV/VO8BTTiy56KKp6buYb/frGC7XsqGX1gN64fPYDBPdunWjTDMNKEWPsYrgN+CfwE\nPAncrKqVIpIBLAdMMaQpZZXVvPjdWh77vICfSio4ZkBXbjxpAEN7dUi1aIZhpBmxWgxdgHNUdY1v\noarWiMjP4ieWES/Kq6p57ft1PDy9gM3F5RyxX2cev2QAI/I6pVo0wzDSlFgVwxRgm2dFRNripOv8\nTlUtMmoaUVldwxuzC3n4swLW7yhlRO+OPHDhUI7Yr0uqRTMMI82JVTE8Bgz3Wd8dpMxIIVXVNbwz\ndwMPfbqctdv2cHCvDvzjnCEc3b9LTOkmDcNovsSqGMR3eKrrQrJJcmlATY3y3vwN/PvT5aws2s2g\nvdvx1C9HcMIB3UwhGIYRE7E26ivdDujH3PXfAivjK5IRCzU1ytSFm3jgk2Us21zC/t3b8vglwzll\nUA9TCIZh1ItYFcM1wEPAXwAFPsXNxWwkh4qqGhZtLGbOmu3MWbud2Wu2s3FnGX27tuahi4bxsyF7\nkWFRTw3DaACxTnDbAoxLkCxGELbsKmPOmh38sNZRBPMLd1JeVQPA3u1zGd67I6MP7MaZB+1t4SsM\nw4gLsc5jyAUuBwYBuZ5yVbWUnHGgqrqGJZt2eS2BOWu3s25bKQDZmcLgnu25ZFRvhu/bkeG9O7BX\n+5YpltgwjKZIrK6k54ElwCnABOBiwIap1pNtuyu8LqE5a7czb91OSiurAejWtgWH9O7IpaPyGN67\nA4P2bk9udmaKJTYMozkQq2Lop6rni8hYVX1WRF4CpiZCsKbO395byDNfrwYgK0MYuHc7Ljy0F8N7\nd2T4vh3o2aGldR4bhpESYlUMle73DhEZjBMvKS+aHUXkBuAKnE7rH3GC8JUDdwHnA9XAY6r6UIwy\nNTqmLdrMM1+v5pzhPRl36L4M6dmeljlmDRiGkR7EqhgmiUhHnFFJk4E2wF8j7SQiPYHrcGZJl7oR\nWccBAvQCDnDnRHSLUZ5Gx9aScm55az4D92rHxHMOIifLOowNw0gvolYMbqC8YjdJzwygbz3O1VJE\nKoFWwAYca+HnqloD3lFPTRZV5f/e/pHi0ipevGKoKQXDMNKSqFsmt/G+tj4nUdX1wD+BtcBGYKeq\nfgzsB1woIvki8qGI9A+2v4hc5dbJLyoqqo8IacHbP6xn6sLN3HTKAPbvYXkPDMNIT2J9ZZ0mIjeJ\nSC8R6eT5RNrJdT+NBfoAewOtReQSoAVQpqojgCdwssLVQVUnqeoIVR3RtWvjzD+8YUcpt7+7kJF5\nnbj8qFiNLcMwjOQRax+DZ77C73zKlMhupdHAKlUtAhCRt4AjgELgTbfO28AzMcrTKKipUW56fR41\nqvzz/IPJtJnJhmGkMbHOfO5Tz/OsBUaJSCugFDgRyAeKgRNwLIVjgWX1PH5a8+zM1XyzYisTzxnC\nvp1bpVocwzCMsMQ68/nSYOWq+ly4/VT1OxF5A5iDkw70B2AS0BJ40R3KWoIznLVJUbClhIkfLuGE\nA7px4aG9Ui2OYRhGRGJ1JR3qs5yL8+Y/BwirGABU9Xbg9oDicuCMGGVoNFRW13Dja3NplZPJxHOH\n2IQ1wzAaBbG6kn7vuy4i7XHCZBhBeHT6CuYX7uTRi4fTrW1u5B0MwzDSgIYOpN8DBB1i2tyZX7iD\n/3y2nLOG7s3pQ/ZKtTiGYRhRE2sfw3s4o5DAUSoDgdfiLVRjp6yymhtfm0eXNi3425jBqRbHMAwj\nJmLtY/inz3IVsEZVC+MoT5PgvqlLKdhSwvOXj6R9q+xUi2MYhhETsSqGtcBGVS0DEJGWIpKnqqvj\nLlkj5ZsVP/HUV6u49PDeHN2/cU7GMwyjeRNrH8PrQI3PerVbZgC7yiq5+fX59OnSmvGnHZBqcQzD\nMOpFrIohS1UrPCvuck58RWq8THhvERt3lvKvCw6mVU6sxphhGEZ6EKtiKBKRMZ4VERkL/BRfkRon\nHy/cxOuzC/ntcf0Yvm/HVItjGIZRb2J9rb0GZ6byw+56IRB0NnRz4qeScm5560cG7tWO60600buG\nYTRuYp3gtgIn5lEbQFR1V2LEajyoKre+/SO7yqp46UrLsWAYRuMnplZMRP4uIh1UtURVd4lIRxG5\nK1HCNQbemmM5FgzDaFrE+np7mqru8Ky42dxOj69IjYf1O0q5Y7LlWDAMo2kRq2LIFJEWnhURaYmT\nbKfZUVOj3Gw5FgzDaILE2vn8AvCpiDyDExrj10QRWbUpYjkWDMNoqsTa+XyviMzHycgmwJ2qOjUh\nkqUxlmPBMIymTMyzsFT1I+AjABE5UkQeUdXfRdityWA5FgzDaOrErBhEZChwEXAhsAp4K95CpTNP\nfrnKciwYhtGkiUoxiMgAYByOQtgKvIozj+H4BMqWdhSXVfLY5wWceEA3y7FgGEaTJVqLYQnwJXCm\nqhYAuHmamxXPfLWa4rIqbjhpQKpFMQzDSBjRDlc9F9gETBeRJ0TkRJzO56gRkRtEZKGILBCRl0Uk\n12fbf0SkJJbjJZudpZU8+dVKThrYncE926daHMMwjIQRlWJQ1bdV9ULgAOBz4Aagu4g8JiInR9pf\nRHoC1wEjVHUwkInjmkJERgAd6id+8nj6q1XsKqvi+tEWC8kwjKZNTBPcVHW3qr6oqj8D9gHmAuOj\n3D0LaCkiWUArYIOIZAL3AX+KRY5ks3NPJU9/tYpTB/Vg0N5mLRiG0bSpd8Q3Vd2mqv9V1ROiqLse\nJy3oWmAjsFNVPwauBSar6sb6ypEMnvpqJbvKq/iDWQuGYTQDkhIKVEQ6AmOBPsDeQGsRuRQ4H/hP\nFPtfJSL5IpJfVFSUWGED2LGngqe/Xs3pQ3pw4F7tknpuwzCMVJCsGNGjgVWqWqSqlThzH/4G9AMK\nRGQ10EpECoLtrKqTVHWEqo7o2jW5eZSf+HIluyuq+MOJNhLJMIzmQbIUw1qcPA6txJkqfCJwv6r2\nUNU8Vc0D9qhqvyTJExXbdlfwv69Xc/qQvSyktmEYzYZoJ7jtwgmaV2cToKoa1seiqt+JyBvAHKAK\n+AGYFKOsSeeJL1eyp7Ka6y0rm2EYzYioFIOqNvh1WVVvB24Ps71NQ88RT7aWlPPsN6s586C96d/d\nrAXDMJoPMcdKAhCRbh3EIV0AAAmFSURBVIB3gpqqro2bRGnCpBkrKausthzOhmE0O2JN7TlGRJbj\nBM/7AlgNfJgAuVLKTyXlPDdzDWMO3pt+3dLKkDEMw0g4sXY+3wmMApapah+cTuSv4y5VivnvFyso\nrzJrwTCM5kmsiqFSVbcCGSKSoarTgaEJkCtlbNlVxvPfruGsoT3p29WsBcMwmh+x9jHsEJE2wAzg\nRRHZgjPKqMnw3y9WUlmt/N6sBcMwmimxWgxjgVKcIHofASuAM+MtVKrYUlzGC9+u4exhPenTpXWq\nxTEMw0gJ0c5jeBh4SVW/8Sl+NjEipY5HP19BVY3y+xPSap6dYRhGUonWYlgO/EtEVovIPW56zybF\npp1lvDRrLecO70nvzmYtGIbRfIk2H8O/VfVw4FhgG/CMiCwWkdvctJ+Nnsc+L6CmRvn9Cda3YBhG\n8ybWfAxrVPUeVR0G/Bw4G1icEMmSyMadpbw8ax3nHbIPvTq1SrU4hmEYKSXWCW7ZInKmiLyIM7Ft\nGU7az0bNo9NXUKPK7463vgXDMIxoO59PAi4CzgBmAa8AV6nq7gTKlhTW7yjl1e/XccGhvcxaMAzD\nIPp5DP8HvATcpKrbEihP0nlkegGKWQuGYRgeoo2uenyiBUkFhdv38Hr+Oi48tBc9O7RMtTiGYRhp\nQbIS9aQlj0wvQBCzFgzDMHxotoph3bY9vJ5fyLiRvdirvVkLhmEYHpqtYnj4swIyMoTfHmfWgmEY\nhi/NUjGs2bqbN+YU8vOR+9KjfW7kHQzDMJoRzVIx/OezArIyhN8ct1+qRTEMw0g7mp1iWP3Tbt7+\nYT0XH9ab7u3MWjAMwwgkaYpBRG4QkYUiskBEXhaRXBF5UUSWumVPi0h2ouV46LPlZGcK1xzXN9Gn\nMgzDaJQkRTGISE/gOmCEqg4GMoFxwIvAAcAQoCVwRSLlWFlUwjs/rOeSw3rTra1ZC4ZhGMGINYNb\nQ8/VUkQqgVbABlX92LNRRGYB+yRSgP98VkBOVgZXH2t9C4ZhGKFIisWgquuBfwJrgY3AzgClkA38\nAicrXB1E5CoRyReR/KKionrJULClhHfnrufSw/Po2rZFvY5hGIbRHEiWK6kjTlrQPsDeQGsRucSn\nyqPADFX9Mtj+qjpJVUeo6oiuXbvWS4YpP24kNzuTq4+xvgXDMIxwJMuVNBpYpapFACLyFnAE8IKI\n3A50Ba5OpADXndifs4f1pHMbsxYMwzDCkSzFsBYYJSKtgFLgRCBfRK4ATgFOVNWaRAthYbUNwzAi\nkxTFoKrficgbwBygCvgBmATsBtYAM0UE4C1VnZAMmQzDMIzgJG1UkqreDtyeqvMbhmEY0SGqmmoZ\nYkJEinCsjPrQBfgpjuIkA5M5OTQ2mRubvGAyJ4tQMvdW1ahG7zQ6xdAQRCRfVUekWo5YMJmTQ2OT\nubHJCyZzsoiHzM0uVpJhGIYRHlMMhmEYhh/NTTFMSrUA9cBkTg6NTebGJi+YzMmiwTI3qz4GwzAM\nIzLNzWIwDMMwItAkFYOInOrmeSgQkfFBtrcQkVfd7d+JSF7ypfSTp5eITBeRxW7Oij8EqXOciOwU\nkbnu57ZUyBog02oR+dGVJz/IdhGRh9zrPF9EhqdCTleW/X2u3VwRKRaR6wPqpPwau3lJtojIAp+y\nTiIyTUSWu98dQ+z7S7fOchH5ZYplvk9Elrj3/W0R6RBi37DPUJJlvkNE1vvc/9ND7Bu2fUmyzK/6\nyLtaROaG2De266yqTeqDk+thBdAXyAHmAQMD6vwWeNxdHge8mmKZ9wKGu8ttgWVBZD4OeD/V1zdA\nptVAlzDbTwc+BAQYBXyXapl9npFNOOO60+oaA8cAw4EFPmX3AuPd5fHAPUH26wSsdL87ussdUyjz\nyUCWu3xPMJmjeYaSLPMdwE1RPDth25dkyhyw/V/AbfG4zk3RYhgJFKjqSlWtAF7Biezqy1jgWXf5\nDeBEcWNypAJV3aiqc9zlXcBioGeq5IkjY4Hn1OFboIOI7JVqoXBida1Q1fpOlEwYqjoD2BZQ7Pu8\nPgucFWTXU4BpqrpNVbcD04BTEyaoD8FkVtWPVbXKXf2WBOdaiZUQ1zkaomlfEkI4md326wLg5Xic\nqykqhp7AOp/1Quo2st467sO7E+icFOki4Lq1hgHfBdl8uIjME5EPRWRQUgULjgIfi8hsEbkqyPZo\n7kUqGEfoP1C6XWOA7qq6EZyXCKBbkDrpeq0Bfo1jOQYj0jOUbK513V9Ph3DZpet1PhrYrKrLQ2yP\n6To3RcUQ7M0/cOhVNHWSjoi0Ad4ErlfV4oDNc3BcHwcD/wHeSbZ8QThSVYcDpwG/E5FjAran3XUW\nkRxgDPB6kM3peI2jJe2uNYCI3IoTOPPFEFUiPUPJ5DFgP2AoTkKxfwWpk5bXGbiI8NZCTNe5KSqG\nQqCXz/o+wIZQdUQkC2hP/czKuCFOFrs3gRdV9a3A7aparKol7vIUIFtEuiRZzECZNrjfW4C3ccxs\nX6K5F8nmNGCOqm4O3JCO19hls8cF535vCVIn7a612wH+M+BidR3dgUTxDCUNVd2sqtXqpAB4IoQs\n6Xids4BzgFdD1Yn1OjdFxfA90F9E+rhvh+OAyQF1JgOeURvnAZ+FenCTgesffApYrKr3h6jTw9MP\nIiIjce7d1uRJWUee1iLS1rOM09m4IKDaZOBSd3TSKJyUrhuTLGogId+s0u0a++D7vP4SeDdInanA\nySLS0XWBnOyWpQQRORX4MzBGVfeEqBPNM5Q0Avq/zg4hSzTtS7IZDSxR1cJgG+t1nZPRm57sD85o\nmGU4owdudcsm4DykALk4roQCYBbQN8XyHoVjjs4H5rqf04FrgGvcOtcCC3FGQXwLHJFimfu6ssxz\n5fJcZ1+ZBXjEvQ8/AiNSLHMrnIa+vU9ZWl1jHKW1EajEeTu9HKf/61Ngufvdya07AnjSZ99fu890\nAXBZimUuwPHFe55nzyjAvYEp4Z6hFMr8vPuczsdp7PcKlNldr9O+pEpmt/x/nmfYp26DrrPNfDYM\nwzD8aIquJMMwDKMBmGIwDMMw/DDFYBiGYfhhisEwDMPwwxSDYRiG4YcpBsOIEyLyTaplMIx4YMNV\nDcMwDD/MYjCMOCEiJamWwTDigSkGwzAMww9TDIZhGIYfphgMwzAMP0wxGIZhGH6YYjAMwzD8sOGq\nhmEYhh9mMRiGYRh+mGIwDMMw/DDFYBiGYfhhisEwDMPwwxSDYRiG4YcpBsMwDMMPUwyGYRiGH6YY\nDMMwDD/+H/6o4vQsIHFcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a55412390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emb_size = 100\n",
    "model_best = BagOfNgram(len(id2token_n1), emb_size)\n",
    "test_acc, model = test_proc(model_best, train_loader_n1, val_loader_n1, test_loader_n1, 0.01, True, 3, 'Adam', 0.1, pl=True, pl_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "index = []\n",
    "for data, lengths, labels in val_loader_n1:\n",
    "    data_batch, length_batch, label_batch = data, lengths, labels\n",
    "    outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "    predicted = outputs.max(1, keepdim=True)[1]\n",
    "    \n",
    "    index += (predicted.numpy() == labels.view_as(predicted).numpy()).tolist()\n",
    "    \n",
    "correct_index = []\n",
    "wrong_index = []\n",
    "for i, val in enumerate(index):\n",
    "    if val[0] == True:\n",
    "        correct_index.append(i)\n",
    "    else:\n",
    "        wrong_index.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprisingly good early effort from Alfred Hitchcock. One of the only original screenplays written by Hitchcock himself, this film shows remarkable story structure. It kicks off with a rousing boxing match in which carnival champ \"One Round\" Jack loses to a challenger from the audience who happens to be a professional prizefighter. The movie then slows down to develop the characters and introduce a love triangle between Jack, his girl and the professional boxer. The rest of the film is a dramatic buildup to the rematch between the two men, this time for the heavyweight crown. Even in this early film, Hitchcock shows his talent for meaningful cinematography and prop placement. An armband bought for the girl by the boxer continues to pop up throughout the movie as a symbol of her unfaithfulness. The only big detractor of this film is that the art of filming a boxing match had not yet been perfected in 1927. The final match, as a result, ends up being somewhat anticlimactic. The story, though, is what carries this film through.\n",
      "\n",
      "Not only is this a great African-American classic comedy, but one of many great American cult classics.I have recently purchased the collection edition of Rudy Ray Moore.If you love the old school karate movies and black comedies, this is for you! They don't make movies like these anymore. My entire family are movie buffs, so this site is an extreme help on solving many debates. I am deployed in Iraq right now. This helps me to stay connected to world that I know in the states. Thank you IMDb.I recommend this site to all my friends. Dolemite rules! Don't just take my word for it, check them out for yourself. Ten lines is a lot for commenting on one movie I think, but if it gets the point across, I'm all for it!\n",
      "\n",
      "Having heard so much about the 1990s Cracker series without seeing any of them, I looked forward to this eagerly. Surely the combination of Jimmie McGovern and Robbie Coltrane could not go wrong. How wrong I was! <br /><br />The polemics, backed by frequent, repetitive and violent flashbacks, were overpowering. The production tried to be super-modern, but the flashing boxes and even the childish font irritated. Robbie Coltrane sleep-walked through the two hours, coming up with unexplained and unlikely \"insights\", and the police were portrayed as one-dimensional bumbling idiots. As a result, the tension never built up and the next-to-final scene (no details for fear of spoilers) was as laughably bad a piece of TV drama as I have seen for a long time.<br /><br />No, I don't want to see any more of these, but I will go back to the DVDs of the 1990s series to see if they match their reputation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "three_list = [i for i in np.random.choice(correct_index, 3)]\n",
    "for i in three_list:\n",
    "    print(val_data[i]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm basing this on my observations of one episode I saw last night (9/27/06). I don't think I'll be watching again. The acting was totally wooden, the plot completely predictable, the ending totally unrealistic -- I mean who would believe a 30 million dollar judgment for the death of a recovering drug addict with terminal cancer? The lead actor (Victor Garber) seemed so uncomfortable, almost embarrassed in his role -- perhaps he realized how bad the writing was!! I fully realize that the drama offered this season is pretty poor, but they can surely find better writers. Maybe they are outsourcing the writing to India or China!! I'll bet we won't be seeing this one next season!\n",
      "\n",
      "I LOVE Don Knotts, let me just say that up-front! He is an enormous talent and the best at what he does, which is portray a nervous, lovably befuddled loser thrown into a position of authority. He is fabulous in this role as Roy Fleming, the Reluctant Astronaut, but the film is pretty dull, really, even though as a kid my brother and I delighted in watching this and his other films. It's still worth watching but really it's a film that is best enjoyed by children. I'd categorize it as 100% family-friendly and something you could sit down and watch with your kids on a family night.<br /><br />As with all of Knotts' films, there's a great cast of beloved character actors and you can't help but smile when Knotts gives one of his shaky, open-mouthed stares, no matter how old and jaded you are.<br /><br />From an adult perspective, one thing I think that is great about this film is how it captures NASA in the 1960s -- all the new modern buildings, the hope, the optimism, the future! And I was surprised at how suave and studly Leslie Neilsen was back then. Only complaint about the story is Roy's love interest, a rather threadbare, unlikeable woman who can't give him the time of day until he becomes a big shot -- if you're like me, you'll be hoping that he gives her the shove-off at the end. Beware -- you'll be whistling the theme tune for days after watching, it's that catchy.\n",
      "\n",
      "FINALLY!!!!!!!!!!! I've been waiting for this film to come out for almost a year, and finally saw it at the premiere in SB. I met a few of the actors, who were really nice and who were great in the movie. i watched the trailer so many times that i didn't know what to expect but got totally sucked in. the film was really beautiful to look at it and the music was good too. i recommend it to anyone who's a ryan donowho fan, and dominique swain was good in it too. the other actors were good also great. I hope it comes out on DVD soon!!!!!<br /><br />i first got into ryan from watching the OC and then saw him in a bunch of good indies like Imaginary Heroes. He is great in this film, and everything that he does that's indie. I also like Dominique but haven't seen her in as much. Hope to see them both in more soon!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "three_list = [i for i in np.random.choice(wrong_index, 3)]\n",
    "for i in three_list:\n",
    "    print(val_data[i]+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
